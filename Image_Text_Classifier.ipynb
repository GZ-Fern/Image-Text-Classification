{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-anRQf3pz7X"
      },
      "source": [
        "# **CNN Image & LSTM Text Classifier**\n",
        "---\n",
        "A deep learning project combining vision and natural languaging processing:\n",
        "*   Convolutional Neural Network for image classification on the CIFAR-100 dataset, achieving ~37.5% test accuracy\n",
        "*   Recurrent Neural Network for text classification on the Reuters dataset, achieving ~64% test accuracy\n",
        "---\n",
        "Fernanda :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yi8Jz9jTpnop"
      },
      "outputs": [],
      "source": [
        "# Importing all required libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8TtdcYhsG3m"
      },
      "outputs": [],
      "source": [
        "# Loading the data - training as well as testing\n",
        "(train_data, test_data), ds_info = tfds.load(\n",
        "    'cifar100',\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "# Preparing the data that can be used by the next step - creating and training the DL model\n",
        "def normalze_image(image, label):\n",
        "  return tf.cast(image, tf.float32) / 255.0, label\n",
        "\n",
        "train_data = train_data.map(normalze_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_data = train_data.cache().shuffle(1000).batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_data = test_data.map(normalze_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_data = test_data.batch(64).cache().prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# The data from TensforFlow and Keras. Each of those 100 integer class labels correspond to the following names, in the correct order\n",
        "fine_labels = ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']\n",
        "\n",
        "# These are the string labels for the 20 superclasses\n",
        "coarse_labels = ['aquatic_mammals', 'fish', 'flowers', 'food_containers', 'fruit_and_vegetables', 'household_electrical_devices', 'household_furniture', 'insects', 'large_carnivores', 'large_man-made_outdoor_things', 'large_natural_outdoor_scenes', 'large_omnivores_and_herbivores', 'medium_mammals', 'non-insect_invertebrates', 'people', 'reptiles', 'small_mammals', 'trees', 'vehicles_1', 'vehicles_2']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_n7nnDCZsk8s"
      },
      "outputs": [],
      "source": [
        "# Visualizing the data by plotting 100 random images, one each for the 100 classes\n",
        "# Drawing 10 images in one row, 10 rows total\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "label_image = {}\n",
        "train_att = tfds.load('cifar100', split='train', as_supervised=True)\n",
        "\n",
        "for image, label in tfds.as_numpy(train_att):\n",
        "  if label not in label_image:\n",
        "    label_image[label] = image\n",
        "  if len(label_image) == 100:\n",
        "    break\n",
        "\n",
        "for idx, (label, image) in enumerate(label_image.items()):\n",
        "  ax = fig.add_subplot(10, 10, idx+1)\n",
        "  ax.imshow(image)\n",
        "  ax.set_title(fine_labels[label], fontsize=7)\n",
        "  ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sTq1YYWstUA"
      },
      "outputs": [],
      "source": [
        "# Creating a DL model for Computer Vision - Convolutional Neural Network\n",
        "cnn_modl = keras.models.Sequential([\n",
        "    keras.Input(shape=(32, 32, 3)),\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(100, activation='softmax')\n",
        "])\n",
        "\n",
        "# Printing the DL model summary\n",
        "cnn_modl.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Amy6SrzJst_K"
      },
      "outputs": [],
      "source": [
        "# Setting the model checkpoints to be saved in a folder in the google drive at at location \"/content/drive/My Drive/Colab Notebooks/cifar/\"\n",
        "checkpoint_path = \"/content/drive/My Drive/Colab Notebooks/cifar/cp.weights.h5\"\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                    save_weights_only=True,\n",
        "                                                    save_best_only=True,\n",
        "                                                    monitor='val_accuracy',\n",
        "                                                    mode='max',\n",
        "                                                    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9DX8R5Ppstvq"
      },
      "outputs": [],
      "source": [
        "# Training the DL model using the training CIFAR-100 data\n",
        "cnn_modl.compile(optimizer='adam',\n",
        "                   loss='sparse_categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "hist = cnn_modl.fit(\n",
        "    train_data,\n",
        "    validation_data=test_data,\n",
        "    epochs=20,\n",
        "    callbacks=[checkpoint_cb]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qltxGAWeyU3b"
      },
      "outputs": [],
      "source": [
        "# Plotting the training/validation accuracy and loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "\n",
        "plt.plot(hist.history['accuracy'], label='Training Accuracy', color='pink')\n",
        "plt.plot(hist.history['val_accuracy'], label='Validation Accuracy', color='purple')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(hist.history['loss'], label='Training Loss', color='pink')\n",
        "plt.plot(hist.history['val_loss'], label='Validation Loss', color='purple')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0FFVXAMkyVAm"
      },
      "outputs": [],
      "source": [
        "# Re-initializing the model\n",
        "reloaded_model = keras.Sequential([\n",
        "    keras.Input(shape=(32, 32, 3)),\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(100, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EfgKMRxEymB6"
      },
      "outputs": [],
      "source": [
        "# Loading the model weights that were saved at - \"/content/drive/My Drive/Colab Notebooks/cifar/\"\n",
        "reloaded_model.load_weights(\"/content/drive/My Drive/Colab Notebooks/cifar/cp.weights.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0vGSuPDNymFw"
      },
      "outputs": [],
      "source": [
        "# Evaluating the trained DL model on the CIFAR-100 test dataset\n",
        "reloaded_model.compile(optimizer='adam',\n",
        "                   loss='sparse_categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "test_loss, test_acc = reloaded_model.evaluate(test_data)\n",
        "print(f\"Test accuracy: {test_acc * 100: .2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4nyTe7hxy292"
      },
      "outputs": [],
      "source": [
        "# Loading the Reuters dataset - using the Keras version\n",
        "# Selecting the vocabulary size while loading the data\n",
        "# The data will be loaded as integer representations for each word\n",
        "vocab_size = 10000\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.reuters.load_data(num_words=vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5vyabZpNzO55"
      },
      "outputs": [],
      "source": [
        "# Preparing the data to be used for the next steps\n",
        "# Each data entry (newswire) can be of different lengths\n",
        "maxlen = 200\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "n12TZnJXzPAm"
      },
      "outputs": [],
      "source": [
        "# Creating a DL model for Natural Language Processing - Recurrent Neural Network / LSTM / GRU\n",
        "rnn_model = keras.Sequential([\n",
        "    keras.Input(shape=(maxlen,)),\n",
        "    keras.layers.Embedding(input_dim=vocab_size, output_dim=64),\n",
        "    keras.layers.LSTM(64),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(46, activation='softmax')\n",
        "])\n",
        "\n",
        "# Printing the DL model summary\n",
        "rnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "permMNlHzPJ5"
      },
      "outputs": [],
      "source": [
        "# Setting the model checkpoints to be saved in a folder in the google drive at at location \"/content/drive/My Drive/Colab Notebooks/reuters/\"\n",
        "reuters_cp_path = \"/content/drive/My Drive/Colab Notebooks/reuters/rnn_reuters.weights.h5\"\n",
        "reuters_cp_cb = tf.keras.callbacks.ModelCheckpoint(filepath=reuters_cp_path,\n",
        "                                                    save_weights_only=True,\n",
        "                                                    save_best_only=True,\n",
        "                                                    monitor='val_accuracy',\n",
        "                                                    mode='max',\n",
        "                                                    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NObYbd4z5NS"
      },
      "outputs": [],
      "source": [
        "# Training the DL model using the training Reuters data\n",
        "rnn_model.compile(optimizer='adam',\n",
        "                   loss='sparse_categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "rnn_hist = rnn_model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    validation_data=(x_test, y_test),\n",
        "    epochs=10,\n",
        "    callbacks=[reuters_cp_cb]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JHZsHT1yz_wO"
      },
      "outputs": [],
      "source": [
        "# Plotting the training and validation...accuracy and loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "\n",
        "plt.plot(rnn_hist.history['accuracy'], label='Training Accuracy', color='pink')\n",
        "plt.plot(rnn_hist.history['val_accuracy'], label='Validation Accuracy', color='purple')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(rnn_hist.history['loss'], label='Training Loss', color='pink')\n",
        "plt.plot(rnn_hist.history['val_loss'], label='Validation Loss', color='purple')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "g_E3O9-r0AFg"
      },
      "outputs": [],
      "source": [
        "# Re-initializing the model\n",
        "reloaded_rnn_model = keras.Sequential([\n",
        "    keras.Input(shape=(maxlen,)),\n",
        "    keras.layers.Embedding(input_dim=vocab_size, output_dim=64),\n",
        "    keras.layers. LSTM(64),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(46, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yC0XcL9B0AVu"
      },
      "outputs": [],
      "source": [
        "# Loading the model weights that were saved at - \"/content/drive/My Drive/Colab Notebooks/reuters/\"\n",
        "reloaded_rnn_model.load_weights(reuters_cp_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpfblukW0NPY"
      },
      "outputs": [],
      "source": [
        "# Evaluating the trained DL model on the Reuters test dataset\n",
        "reloaded_rnn_model.compile(optimizer='adam',\n",
        "                   loss='sparse_categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "test_loss, test_acc = reloaded_rnn_model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc * 100: .2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}